{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f96559f6",
   "metadata": {},
   "source": [
    "# Tutorial de Keras, primera red neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1266bae",
   "metadata": {},
   "source": [
    "Primero de todo, se cargan las librerías y los datos. En este caso se descargan los datos de un problema de clasificación binaria para detectar diabetes (Y=1, con diabetes; 0, sin diabetes) a partir de unas variables independientes (X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8ab1bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt \n",
    "\n",
    "#from tensorflow.keras.models import Sequential \n",
    "\n",
    "#from tensorflow.keras.layers import Dense \n",
    "\n",
    "# Carga del dataset \n",
    "\n",
    "URL_FICHERO='https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv' \n",
    "\n",
    "dataset = loadtxt(URL_FICHERO, delimiter=',') \n",
    "\n",
    "# Separación de las variables independientes de la dependiente \n",
    "\n",
    "X = dataset[:,0:8] \n",
    "\n",
    "y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce38661b-f9a7-49d2-9e16-9ed9df8939a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3a7346f-d6e9-4bff-adfb-441426e5c59d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff434a9c-acd4-479b-9f1b-d2ae41923808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.,\n",
       "       1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9e93bd1-16da-4cf2-b552-982bea2f778e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18570d44-b047-4c9c-9a86-afceba99f815",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'numpy.float64' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'numpy.float64' has no len()"
     ]
    }
   ],
   "source": [
    "len(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48358fb1",
   "metadata": {},
   "source": [
    "En el siguiente paso se define el modelo como un modelo secuencial con tres capas. \n",
    "\n",
    "- La primera capa contiene 12 neuronas y define también la capa de entrada con el atributo input_dim. La función de activación es la que se suele usar por defecto excepto en la capa de salida, la ReLU.\n",
    "\n",
    "- La segunda capa tiene ocho neuronas y función de activación ReLU.\n",
    "\n",
    "- Por último, la capa de salida tiene una sola neurona, y, como función de activación, la Sigmoid. La Sigmoid sirve para problemas de clasificación binaria, como este caso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081a0cf4",
   "metadata": {},
   "source": [
    "Posteriormente a definir el modelo se realiza la compilación. Para ello se definen una función de coste, un optimizador y una métrica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5944ce62",
   "metadata": {},
   "source": [
    "Por último, se definen las variables entrada X y salida y. Se define 150 como el número de épocas (todas las muestras se tienen en cuenta 150 veces). El tamaño de lote se define en 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d1192be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "77/77 [==============================] - 0s 484us/step - loss: 15.1031 - accuracy: 0.3490\n",
      "Epoch 2/150\n",
      "77/77 [==============================] - 0s 386us/step - loss: 2.4956 - accuracy: 0.4883\n",
      "Epoch 3/150\n",
      "77/77 [==============================] - 0s 385us/step - loss: 1.1895 - accuracy: 0.5182\n",
      "Epoch 4/150\n",
      "77/77 [==============================] - 0s 391us/step - loss: 0.8575 - accuracy: 0.6263\n",
      "Epoch 5/150\n",
      "77/77 [==============================] - 0s 364us/step - loss: 0.7344 - accuracy: 0.6432\n",
      "Epoch 6/150\n",
      "77/77 [==============================] - 0s 375us/step - loss: 0.6877 - accuracy: 0.6406\n",
      "Epoch 7/150\n",
      "77/77 [==============================] - 0s 357us/step - loss: 0.6718 - accuracy: 0.6523\n",
      "Epoch 8/150\n",
      "77/77 [==============================] - 0s 382us/step - loss: 0.6644 - accuracy: 0.6510\n",
      "Epoch 9/150\n",
      "77/77 [==============================] - 0s 383us/step - loss: 0.6590 - accuracy: 0.6536\n",
      "Epoch 10/150\n",
      "77/77 [==============================] - 0s 417us/step - loss: 0.6570 - accuracy: 0.6549\n",
      "Epoch 11/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6561 - accuracy: 0.6536\n",
      "Epoch 12/150\n",
      "77/77 [==============================] - 0s 380us/step - loss: 0.6552 - accuracy: 0.6523\n",
      "Epoch 13/150\n",
      "77/77 [==============================] - 0s 410us/step - loss: 0.6506 - accuracy: 0.6549\n",
      "Epoch 14/150\n",
      "77/77 [==============================] - 0s 382us/step - loss: 0.6484 - accuracy: 0.6576\n",
      "Epoch 15/150\n",
      "77/77 [==============================] - 0s 387us/step - loss: 0.6478 - accuracy: 0.6562\n",
      "Epoch 16/150\n",
      "77/77 [==============================] - 0s 364us/step - loss: 0.6454 - accuracy: 0.6589\n",
      "Epoch 17/150\n",
      "77/77 [==============================] - 0s 376us/step - loss: 0.6447 - accuracy: 0.6576\n",
      "Epoch 18/150\n",
      "77/77 [==============================] - 0s 379us/step - loss: 0.6457 - accuracy: 0.6562\n",
      "Epoch 19/150\n",
      "77/77 [==============================] - 0s 379us/step - loss: 0.6440 - accuracy: 0.6549\n",
      "Epoch 20/150\n",
      "77/77 [==============================] - 0s 369us/step - loss: 0.6433 - accuracy: 0.6576\n",
      "Epoch 21/150\n",
      "77/77 [==============================] - 0s 393us/step - loss: 0.6399 - accuracy: 0.6589\n",
      "Epoch 22/150\n",
      "77/77 [==============================] - 0s 384us/step - loss: 0.6365 - accuracy: 0.6602\n",
      "Epoch 23/150\n",
      "77/77 [==============================] - 0s 366us/step - loss: 0.6416 - accuracy: 0.6484\n",
      "Epoch 24/150\n",
      "77/77 [==============================] - 0s 362us/step - loss: 0.6356 - accuracy: 0.6549\n",
      "Epoch 25/150\n",
      "77/77 [==============================] - 0s 374us/step - loss: 0.6317 - accuracy: 0.6589\n",
      "Epoch 26/150\n",
      "77/77 [==============================] - 0s 370us/step - loss: 0.6299 - accuracy: 0.6641\n",
      "Epoch 27/150\n",
      "77/77 [==============================] - 0s 389us/step - loss: 0.6287 - accuracy: 0.6602\n",
      "Epoch 28/150\n",
      "77/77 [==============================] - 0s 388us/step - loss: 0.6303 - accuracy: 0.6732\n",
      "Epoch 29/150\n",
      "77/77 [==============================] - 0s 370us/step - loss: 0.6234 - accuracy: 0.6589\n",
      "Epoch 30/150\n",
      "77/77 [==============================] - 0s 373us/step - loss: 0.6228 - accuracy: 0.6706\n",
      "Epoch 31/150\n",
      "77/77 [==============================] - 0s 390us/step - loss: 0.6185 - accuracy: 0.6745\n",
      "Epoch 32/150\n",
      "77/77 [==============================] - 0s 367us/step - loss: 0.6197 - accuracy: 0.6719\n",
      "Epoch 33/150\n",
      "77/77 [==============================] - 0s 353us/step - loss: 0.6172 - accuracy: 0.6862\n",
      "Epoch 34/150\n",
      "77/77 [==============================] - 0s 367us/step - loss: 0.6164 - accuracy: 0.6654\n",
      "Epoch 35/150\n",
      "77/77 [==============================] - 0s 376us/step - loss: 0.6136 - accuracy: 0.6706\n",
      "Epoch 36/150\n",
      "77/77 [==============================] - 0s 371us/step - loss: 0.6097 - accuracy: 0.6784\n",
      "Epoch 37/150\n",
      "77/77 [==============================] - 0s 366us/step - loss: 0.6079 - accuracy: 0.6940\n",
      "Epoch 38/150\n",
      "77/77 [==============================] - 0s 378us/step - loss: 0.6056 - accuracy: 0.6940\n",
      "Epoch 39/150\n",
      "77/77 [==============================] - 0s 370us/step - loss: 0.6037 - accuracy: 0.6914\n",
      "Epoch 40/150\n",
      "77/77 [==============================] - 0s 361us/step - loss: 0.6005 - accuracy: 0.6979\n",
      "Epoch 41/150\n",
      "77/77 [==============================] - 0s 365us/step - loss: 0.6007 - accuracy: 0.6914\n",
      "Epoch 42/150\n",
      "77/77 [==============================] - 0s 367us/step - loss: 0.5996 - accuracy: 0.6979\n",
      "Epoch 43/150\n",
      "77/77 [==============================] - 0s 358us/step - loss: 0.5970 - accuracy: 0.7083\n",
      "Epoch 44/150\n",
      "77/77 [==============================] - 0s 375us/step - loss: 0.5901 - accuracy: 0.7018\n",
      "Epoch 45/150\n",
      "77/77 [==============================] - 0s 354us/step - loss: 0.5883 - accuracy: 0.7253\n",
      "Epoch 46/150\n",
      "77/77 [==============================] - 0s 361us/step - loss: 0.5871 - accuracy: 0.7253\n",
      "Epoch 47/150\n",
      "77/77 [==============================] - 0s 386us/step - loss: 0.5818 - accuracy: 0.7148\n",
      "Epoch 48/150\n",
      "77/77 [==============================] - 0s 355us/step - loss: 0.5814 - accuracy: 0.7174\n",
      "Epoch 49/150\n",
      "77/77 [==============================] - 0s 363us/step - loss: 0.5863 - accuracy: 0.6992\n",
      "Epoch 50/150\n",
      "77/77 [==============================] - 0s 380us/step - loss: 0.5802 - accuracy: 0.7083\n",
      "Epoch 51/150\n",
      "77/77 [==============================] - 0s 360us/step - loss: 0.5758 - accuracy: 0.7214\n",
      "Epoch 52/150\n",
      "77/77 [==============================] - 0s 384us/step - loss: 0.5736 - accuracy: 0.7214\n",
      "Epoch 53/150\n",
      "77/77 [==============================] - 0s 385us/step - loss: 0.5784 - accuracy: 0.7383\n",
      "Epoch 54/150\n",
      "77/77 [==============================] - 0s 386us/step - loss: 0.5698 - accuracy: 0.7305\n",
      "Epoch 55/150\n",
      "77/77 [==============================] - 0s 377us/step - loss: 0.5685 - accuracy: 0.7448\n",
      "Epoch 56/150\n",
      "77/77 [==============================] - 0s 374us/step - loss: 0.5650 - accuracy: 0.7422\n",
      "Epoch 57/150\n",
      "77/77 [==============================] - 0s 371us/step - loss: 0.5619 - accuracy: 0.7370\n",
      "Epoch 58/150\n",
      "77/77 [==============================] - 0s 368us/step - loss: 0.5634 - accuracy: 0.7318\n",
      "Epoch 59/150\n",
      "77/77 [==============================] - 0s 373us/step - loss: 0.5661 - accuracy: 0.7292\n",
      "Epoch 60/150\n",
      "77/77 [==============================] - 0s 372us/step - loss: 0.5704 - accuracy: 0.7201\n",
      "Epoch 61/150\n",
      "77/77 [==============================] - 0s 372us/step - loss: 0.5564 - accuracy: 0.7292\n",
      "Epoch 62/150\n",
      "77/77 [==============================] - 0s 366us/step - loss: 0.5579 - accuracy: 0.7240\n",
      "Epoch 63/150\n",
      "77/77 [==============================] - 0s 372us/step - loss: 0.5544 - accuracy: 0.7396\n",
      "Epoch 64/150\n",
      "77/77 [==============================] - 0s 366us/step - loss: 0.5524 - accuracy: 0.7370\n",
      "Epoch 65/150\n",
      "77/77 [==============================] - 0s 371us/step - loss: 0.5528 - accuracy: 0.7318\n",
      "Epoch 66/150\n",
      "77/77 [==============================] - 0s 363us/step - loss: 0.5543 - accuracy: 0.7435\n",
      "Epoch 67/150\n",
      "77/77 [==============================] - 0s 366us/step - loss: 0.5501 - accuracy: 0.7240\n",
      "Epoch 68/150\n",
      "77/77 [==============================] - 0s 364us/step - loss: 0.5508 - accuracy: 0.7318\n",
      "Epoch 69/150\n",
      "77/77 [==============================] - 0s 360us/step - loss: 0.5471 - accuracy: 0.7448\n",
      "Epoch 70/150\n",
      "77/77 [==============================] - 0s 365us/step - loss: 0.5471 - accuracy: 0.7383\n",
      "Epoch 71/150\n",
      "77/77 [==============================] - 0s 360us/step - loss: 0.5497 - accuracy: 0.7318\n",
      "Epoch 72/150\n",
      "77/77 [==============================] - 0s 355us/step - loss: 0.5484 - accuracy: 0.7331\n",
      "Epoch 73/150\n",
      "77/77 [==============================] - 0s 380us/step - loss: 0.5498 - accuracy: 0.7292\n",
      "Epoch 74/150\n",
      "77/77 [==============================] - 0s 367us/step - loss: 0.5456 - accuracy: 0.7318\n",
      "Epoch 75/150\n",
      "77/77 [==============================] - 0s 355us/step - loss: 0.5405 - accuracy: 0.7474\n",
      "Epoch 76/150\n",
      "77/77 [==============================] - 0s 356us/step - loss: 0.5495 - accuracy: 0.7409\n",
      "Epoch 77/150\n",
      "77/77 [==============================] - 0s 363us/step - loss: 0.5382 - accuracy: 0.7448\n",
      "Epoch 78/150\n",
      "77/77 [==============================] - 0s 377us/step - loss: 0.5471 - accuracy: 0.7357\n",
      "Epoch 79/150\n",
      "77/77 [==============================] - 0s 363us/step - loss: 0.5417 - accuracy: 0.7409\n",
      "Epoch 80/150\n",
      "77/77 [==============================] - 0s 356us/step - loss: 0.5406 - accuracy: 0.7487\n",
      "Epoch 81/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 382us/step - loss: 0.5408 - accuracy: 0.7396\n",
      "Epoch 82/150\n",
      "77/77 [==============================] - 0s 365us/step - loss: 0.5363 - accuracy: 0.7409\n",
      "Epoch 83/150\n",
      "77/77 [==============================] - 0s 368us/step - loss: 0.5386 - accuracy: 0.7435\n",
      "Epoch 84/150\n",
      "77/77 [==============================] - 0s 358us/step - loss: 0.5328 - accuracy: 0.7396\n",
      "Epoch 85/150\n",
      "77/77 [==============================] - 0s 347us/step - loss: 0.5367 - accuracy: 0.7435\n",
      "Epoch 86/150\n",
      "77/77 [==============================] - 0s 351us/step - loss: 0.5285 - accuracy: 0.7409\n",
      "Epoch 87/150\n",
      "77/77 [==============================] - 0s 341us/step - loss: 0.5340 - accuracy: 0.7487\n",
      "Epoch 88/150\n",
      "77/77 [==============================] - 0s 329us/step - loss: 0.5345 - accuracy: 0.7422\n",
      "Epoch 89/150\n",
      "77/77 [==============================] - 0s 343us/step - loss: 0.5262 - accuracy: 0.7513\n",
      "Epoch 90/150\n",
      "77/77 [==============================] - 0s 353us/step - loss: 0.5285 - accuracy: 0.7474\n",
      "Epoch 91/150\n",
      "77/77 [==============================] - 0s 346us/step - loss: 0.5292 - accuracy: 0.7357\n",
      "Epoch 92/150\n",
      "77/77 [==============================] - 0s 357us/step - loss: 0.5247 - accuracy: 0.7474\n",
      "Epoch 93/150\n",
      "77/77 [==============================] - 0s 345us/step - loss: 0.5323 - accuracy: 0.7292\n",
      "Epoch 94/150\n",
      "77/77 [==============================] - 0s 341us/step - loss: 0.5326 - accuracy: 0.7474\n",
      "Epoch 95/150\n",
      "77/77 [==============================] - 0s 352us/step - loss: 0.5242 - accuracy: 0.7448\n",
      "Epoch 96/150\n",
      "77/77 [==============================] - 0s 341us/step - loss: 0.5217 - accuracy: 0.7474\n",
      "Epoch 97/150\n",
      "77/77 [==============================] - 0s 348us/step - loss: 0.5277 - accuracy: 0.7305\n",
      "Epoch 98/150\n",
      "77/77 [==============================] - 0s 420us/step - loss: 0.5262 - accuracy: 0.7461\n",
      "Epoch 99/150\n",
      "77/77 [==============================] - 0s 364us/step - loss: 0.5292 - accuracy: 0.7409\n",
      "Epoch 100/150\n",
      "77/77 [==============================] - 0s 370us/step - loss: 0.5217 - accuracy: 0.7409\n",
      "Epoch 101/150\n",
      "77/77 [==============================] - 0s 357us/step - loss: 0.5208 - accuracy: 0.7539\n",
      "Epoch 102/150\n",
      "77/77 [==============================] - 0s 348us/step - loss: 0.5196 - accuracy: 0.7396\n",
      "Epoch 103/150\n",
      "77/77 [==============================] - 0s 356us/step - loss: 0.5165 - accuracy: 0.7422\n",
      "Epoch 104/150\n",
      "77/77 [==============================] - 0s 367us/step - loss: 0.5192 - accuracy: 0.7435\n",
      "Epoch 105/150\n",
      "77/77 [==============================] - 0s 369us/step - loss: 0.5166 - accuracy: 0.7396\n",
      "Epoch 106/150\n",
      "77/77 [==============================] - 0s 368us/step - loss: 0.5209 - accuracy: 0.7448\n",
      "Epoch 107/150\n",
      "77/77 [==============================] - 0s 359us/step - loss: 0.5199 - accuracy: 0.7396\n",
      "Epoch 108/150\n",
      "77/77 [==============================] - 0s 356us/step - loss: 0.5102 - accuracy: 0.7461\n",
      "Epoch 109/150\n",
      "77/77 [==============================] - 0s 343us/step - loss: 0.5182 - accuracy: 0.7448\n",
      "Epoch 110/150\n",
      "77/77 [==============================] - 0s 351us/step - loss: 0.5178 - accuracy: 0.7383\n",
      "Epoch 111/150\n",
      "77/77 [==============================] - 0s 344us/step - loss: 0.5136 - accuracy: 0.7513\n",
      "Epoch 112/150\n",
      "77/77 [==============================] - 0s 338us/step - loss: 0.5207 - accuracy: 0.7487\n",
      "Epoch 113/150\n",
      "77/77 [==============================] - 0s 341us/step - loss: 0.5165 - accuracy: 0.7435\n",
      "Epoch 114/150\n",
      "77/77 [==============================] - 0s 349us/step - loss: 0.5079 - accuracy: 0.7409\n",
      "Epoch 115/150\n",
      "77/77 [==============================] - 0s 349us/step - loss: 0.5151 - accuracy: 0.7552\n",
      "Epoch 116/150\n",
      "77/77 [==============================] - 0s 346us/step - loss: 0.5166 - accuracy: 0.7474\n",
      "Epoch 117/150\n",
      "77/77 [==============================] - 0s 352us/step - loss: 0.5211 - accuracy: 0.7526\n",
      "Epoch 118/150\n",
      "77/77 [==============================] - 0s 335us/step - loss: 0.5175 - accuracy: 0.7539\n",
      "Epoch 119/150\n",
      "77/77 [==============================] - 0s 361us/step - loss: 0.5139 - accuracy: 0.7461\n",
      "Epoch 120/150\n",
      "77/77 [==============================] - 0s 350us/step - loss: 0.5088 - accuracy: 0.7578\n",
      "Epoch 121/150\n",
      "77/77 [==============================] - 0s 376us/step - loss: 0.5083 - accuracy: 0.7591\n",
      "Epoch 122/150\n",
      "77/77 [==============================] - 0s 398us/step - loss: 0.5110 - accuracy: 0.7539\n",
      "Epoch 123/150\n",
      "77/77 [==============================] - 0s 366us/step - loss: 0.5068 - accuracy: 0.7578\n",
      "Epoch 124/150\n",
      "77/77 [==============================] - 0s 393us/step - loss: 0.5044 - accuracy: 0.7474\n",
      "Epoch 125/150\n",
      "77/77 [==============================] - 0s 370us/step - loss: 0.5204 - accuracy: 0.7474\n",
      "Epoch 126/150\n",
      "77/77 [==============================] - 0s 366us/step - loss: 0.5090 - accuracy: 0.7565\n",
      "Epoch 127/150\n",
      "77/77 [==============================] - 0s 368us/step - loss: 0.5138 - accuracy: 0.7357\n",
      "Epoch 128/150\n",
      "77/77 [==============================] - 0s 390us/step - loss: 0.5110 - accuracy: 0.7474\n",
      "Epoch 129/150\n",
      "77/77 [==============================] - 0s 363us/step - loss: 0.5122 - accuracy: 0.7513\n",
      "Epoch 130/150\n",
      "77/77 [==============================] - 0s 361us/step - loss: 0.5102 - accuracy: 0.7617\n",
      "Epoch 131/150\n",
      "77/77 [==============================] - 0s 356us/step - loss: 0.5082 - accuracy: 0.7448\n",
      "Epoch 132/150\n",
      "77/77 [==============================] - 0s 363us/step - loss: 0.5044 - accuracy: 0.7539\n",
      "Epoch 133/150\n",
      "77/77 [==============================] - 0s 365us/step - loss: 0.5131 - accuracy: 0.7396\n",
      "Epoch 134/150\n",
      "77/77 [==============================] - 0s 350us/step - loss: 0.5071 - accuracy: 0.7435\n",
      "Epoch 135/150\n",
      "77/77 [==============================] - 0s 341us/step - loss: 0.5032 - accuracy: 0.7604\n",
      "Epoch 136/150\n",
      "77/77 [==============================] - 0s 347us/step - loss: 0.5018 - accuracy: 0.7630\n",
      "Epoch 137/150\n",
      "77/77 [==============================] - 0s 351us/step - loss: 0.5083 - accuracy: 0.7578\n",
      "Epoch 138/150\n",
      "77/77 [==============================] - 0s 347us/step - loss: 0.5060 - accuracy: 0.7526\n",
      "Epoch 139/150\n",
      "77/77 [==============================] - 0s 347us/step - loss: 0.5039 - accuracy: 0.7526\n",
      "Epoch 140/150\n",
      "77/77 [==============================] - 0s 360us/step - loss: 0.5023 - accuracy: 0.7591\n",
      "Epoch 141/150\n",
      "77/77 [==============================] - 0s 356us/step - loss: 0.4988 - accuracy: 0.7526\n",
      "Epoch 142/150\n",
      "77/77 [==============================] - 0s 352us/step - loss: 0.5032 - accuracy: 0.7578\n",
      "Epoch 143/150\n",
      "77/77 [==============================] - 0s 364us/step - loss: 0.4986 - accuracy: 0.7552\n",
      "Epoch 144/150\n",
      "77/77 [==============================] - 0s 348us/step - loss: 0.4970 - accuracy: 0.7578\n",
      "Epoch 145/150\n",
      "77/77 [==============================] - 0s 355us/step - loss: 0.5013 - accuracy: 0.7617\n",
      "Epoch 146/150\n",
      "77/77 [==============================] - 0s 342us/step - loss: 0.4984 - accuracy: 0.7695\n",
      "Epoch 147/150\n",
      "77/77 [==============================] - 0s 333us/step - loss: 0.5103 - accuracy: 0.7500\n",
      "Epoch 148/150\n",
      "77/77 [==============================] - 0s 351us/step - loss: 0.5062 - accuracy: 0.7500\n",
      "Epoch 149/150\n",
      "77/77 [==============================] - 0s 350us/step - loss: 0.5000 - accuracy: 0.7643\n",
      "Epoch 150/150\n",
      "77/77 [==============================] - 0s 343us/step - loss: 0.4988 - accuracy: 0.7513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x287c55750>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definición del modelo\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compilación del modelo\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Ajuste del modelo a los datos\n",
    "model.fit(X, y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75088f1",
   "metadata": {},
   "source": [
    "Después de entrenar el modelo, en este caso se mide la métrica final de accuracy y se obtienen las predicciones y los valores reales de las cinco primeras muestras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10be21a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 423us/step - loss: 0.4997 - accuracy: 0.7682\n",
      "Accuracy: 76.82\n",
      "24/24 [==============================] - 0s 376us/step\n",
      "X => [6.0, 148.0, 72.0, 35.0, 0.0, 33.6, 0.627, 50.0] Ypred => 1 (Yreal 1)\n",
      "X => [1.0, 85.0, 66.0, 29.0, 0.0, 26.6, 0.351, 31.0] Ypred => 0 (Yreal 0)\n",
      "X => [8.0, 183.0, 64.0, 0.0, 0.0, 23.3, 0.672, 32.0] Ypred => 1 (Yreal 1)\n",
      "X => [1.0, 89.0, 66.0, 23.0, 94.0, 28.1, 0.167, 21.0] Ypred => 0 (Yreal 0)\n",
      "X => [0.0, 137.0, 40.0, 35.0, 168.0, 43.1, 2.288, 33.0] Ypred => 1 (Yreal 1)\n"
     ]
    }
   ],
   "source": [
    "# Evaluación del modelo\n",
    "_, accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n",
    "\n",
    "# Realización de predicciones\n",
    "predictions = (model.predict(X) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Obtención de los cinco primeros casos\n",
    "for i in range(5):    \n",
    "    print('X => %s Ypred => %d (Yreal %d)' % (X[i].tolist(), predictions[i], y[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
